{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "sys.path.append(os.path.abspath((\"../tools/\")))\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data, load_classifier_and_data, test_classifier\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_project_dataset.pkl', 'rb') as src:\n",
    "    data_dict = pickle.load(src)\n",
    "\n",
    "feature_set = set()\n",
    "\n",
    "# find all unique feature\n",
    "data_items = data_dict.items()\n",
    "for employee, features in data_items:\n",
    "    for feature in features:\n",
    "        feature_set.add(feature)\n",
    "\n",
    "# validate that all records have those features.\n",
    "for employee, features in data_items:\n",
    "    contains_all_features = all([f in feature_set for f in features.keys()])\n",
    "    if not contains_all_features:\n",
    "        raise KeyError(\"features missing...\")\n",
    "\n",
    "feature_set.remove('poi')\n",
    "feature_set.remove('email_address') # feature will not work in featureFormat\n",
    "\n",
    "# Create new features\n",
    "for emp in data_dict:\n",
    "    if not data_dict[emp]['from_poi_to_this_person'] == 'NaN' \\\n",
    "        and data_dict[emp]['from_this_person_to_poi'] == 'NaN':\n",
    "        data_dict[emp]['from_ratio'] = data_dict[emp]['from_poi_to_this_person'] / data_dict[emp]['to_messages']\n",
    "        data_dict[emp]['to_ratio'] = data_dict[emp]['from_this_person_to_poi'] / data_dict[emp]['from_messages']\n",
    "    else:\n",
    "        data_dict[emp]['from_ratio'] = 'NaN'\n",
    "        data_dict[emp]['to_ratio'] = 'NaN'\n",
    "\n",
    "feature_set.add('from_ratio')\n",
    "feature_set.add('to_ratio')\n",
    "set_list = list(feature_set)\n",
    "set_list.sort()\n",
    "features_list = ['poi'] + set_list\n",
    "\n",
    "# Remove some meaningless entries\n",
    "for name in ('TOTAL', 'THE TRAVEL AGENCY IN THE PARK'):\n",
    "    data_dict.pop(name)\n",
    "\n",
    "# Format data for ML activities\n",
    "def format_and_split(data_dict, features_list):\n",
    "    return targetFeatureSplit(\n",
    "        featureFormat(\n",
    "            data_dict,\n",
    "            features_list\n",
    "        )\n",
    "    )\n",
    "labels, features = format_and_split(data_dict, features_list)\n",
    "labels, features = np.array(labels), np.array(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_extractor(best_params_, estimator_name):\n",
    "    \"\"\" \n",
    "    param_extractor extracts and formats the best hyper-parameters\n",
    "    from the best_params_ attribute of GridSearchCV\n",
    "    \"\"\"\n",
    "\n",
    "    if not estimator_name.endswith(\"__\"):\n",
    "        estimator_name = estimator_name + \"__\"\n",
    "    \n",
    "    return {\n",
    "    k.replace(estimator_name, \"\"): v\n",
    "    for k, v in best_params_.items()\n",
    "    if k.startswith(estimator_name)\n",
    "    }\n",
    "\n",
    "def scorer(test_labels, test_predictions):\n",
    "    \"\"\"\n",
    "    scorer generates accuracy, precision, and recall\n",
    "    metrics for a given model\n",
    "    \"\"\"\n",
    "    return dict(\n",
    "        accuracy=accuracy_score(test_labels, test_predictions),\n",
    "        precision=precision_score(test_labels, test_predictions),\n",
    "        recall=recall_score(test_labels, test_predictions),\n",
    "    )\n",
    "\n",
    "def best_features_extractor(selector, features_list):\n",
    "    best_features = []\n",
    "    for kbest in selector.get_support(indices=True):\n",
    "        best_features.append(features_list[1:][kbest])\n",
    "    return best_features\n",
    "\n",
    "def set_estimator_params(pipeline, best_params_):\n",
    "    # Update selector params\n",
    "    pipeline.steps[1][1].set_params(**param_extractor(best_params_, 'selector'))\n",
    "    pipeline.steps[2][1].set_params(**param_extractor(best_params_, 'classifier'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating various classifiers.\n",
      "('Estimator: ', 'GaussianNB', 'scores: ', {'recall': 0.2800000000000001, 'precision': 0.5166666666666667, 'accuracy': 0.8611111111111113})\n",
      "('Estimator: ', 'RandomForestClassifier', 'scores: ', {'recall': 0.31999999999999995, 'precision': 0.4208333333333334, 'accuracy': 0.7833333333333333})\n",
      "('Estimator: ', 'KNeighborsClassifier', 'scores: ', {'recall': 0.34, 'precision': 0.3047916666666667, 'accuracy': 0.761111111111111})\n",
      "('Estimator: ', 'DecisionTreeClassifier', 'scores: ', {'recall': 0.32, 'precision': 0.3191666666666667, 'accuracy': 0.7805555555555554})\n",
      "('Estimator: ', 'AdaBoostClassifier', 'scores: ', {'recall': 0.36000000000000004, 'precision': 0.31507936507936507, 'accuracy': 0.7722222222222221})\n",
      "Performing synthetic tests with stratified sampling.\n",
      "('GaussianNB', {'recall': 0.2219999999999998, 'precision': 0.4461904761904762, 'accuracy': 0.8591666666666663}, ['bonus', 'deferred_income', 'exercised_stock_options', 'salary', 'total_stock_value'])\n",
      "('RandomForestClassifier', {'recall': 0.09799999999999999, 'precision': 0.23792857142857138, 'accuracy': 0.8438888888888895}, ['bonus', 'expenses', 'from_poi_to_this_person', 'from_ratio', 'from_this_person_to_poi', 'other', 'salary', 'shared_receipt_with_poi', 'total_stock_value'])\n",
      "('KNeighborsClassifier', {'recall': 0.12199999999999996, 'precision': 0.37, 'accuracy': 0.8630555555555559}, ['bonus', 'exercised_stock_options', 'salary', 'shared_receipt_with_poi', 'total_stock_value'])\n",
      "('DecisionTreeClassifier', {'recall': 0.22999999999999976, 'precision': 0.3632857142857142, 'accuracy': 0.8388888888888891}, ['exercised_stock_options', 'salary', 'total_stock_value'])\n",
      "('AdaBoostClassifier', {'recall': 0.2479999999999998, 'precision': 0.35396428571428573, 'accuracy': 0.834166666666667}, ['bonus', 'exercised_stock_options', 'from_this_person_to_poi', 'loan_advances', 'long_term_incentive', 'total_payments', 'total_stock_value'])\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler() # Changed from StandardScaler, MinMax \n",
    "# I dont think we can reuse this...\n",
    "# selector = SelectKBest() # k, score_func\n",
    "\n",
    "gaussian = GaussianNB() # priors, var_smoothing\n",
    "random_forest = RandomForestClassifier() # n_estimators, \n",
    "neighbors = KNeighborsClassifier()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "ada_boost = AdaBoostClassifier()\n",
    "\n",
    "estimators = [{\n",
    "\t'name': \"GaussianNB\",\n",
    "\t'classifier': Pipeline([\n",
    "\t\t('scaler', scaler),\n",
    "\t\t('selector', SelectKBest()),\n",
    "\t\t('classifier', gaussian)\n",
    "\t]),\n",
    "\t'param_grid': {\n",
    "\t\t\"selector__k\": [5, 7, 9],\n",
    "\t\t\"classifier__var_smoothing\": np.logspace(0,-9, num=20),\n",
    "\t}\n",
    "}, {\n",
    "\t'name': 'RandomForestClassifier',\n",
    "\t'classifier': Pipeline([\n",
    "\t\t('scaler', scaler),\n",
    "\t\t('selector', SelectKBest()),\n",
    "\t\t('classifier', random_forest)\n",
    "\t]),\n",
    "\t'param_grid': {\n",
    "\t\t\"selector__k\": [5, 7, 9],\n",
    "\t\t\"selector__score_func\": [f_classif, mutual_info_classif, chi2],\n",
    "\t\t\"classifier__n_estimators\": [110, 115, 120, 125],\n",
    "\t\t\"classifier__criterion\": [\"gini\", \"entropy\"],\n",
    "\t\t\"classifier__min_samples_split\": [2, 3, 5],\n",
    "\t}\n",
    "}, {\n",
    "\t'name': 'KNeighborsClassifier',\n",
    "\t'classifier': Pipeline([\n",
    "\t\t('scaler', scaler),\n",
    "\t\t('selector', SelectKBest()),\n",
    "\t\t('classifier', neighbors)\n",
    "\t]),\n",
    "\t'param_grid': {\n",
    "\t\t\"selector__k\": [5, 7, 9],\n",
    "\t\t\"selector__score_func\": [f_classif, mutual_info_classif, chi2],\n",
    "\t\t\"classifier__n_neighbors\": [3, 5, 7, 9],\n",
    "\t\t\"classifier__weights\": ['uniform', 'distance'],\n",
    "\t\t\"classifier__algorithm\": ['ball_tree', 'kd_tree', 'brute'],\n",
    "\t\t\"classifier__metric\": ['minkowski', 'cityblock', 'euclidean'],\n",
    "\t}\n",
    "}, {\n",
    "\t'name': 'DecisionTreeClassifier',\n",
    "\t'classifier': Pipeline([\n",
    "\t\t('scaler', scaler),\n",
    "\t\t('selector', SelectKBest()),\n",
    "\t\t('classifier', decision_tree)\n",
    "\t]),\n",
    "\t'param_grid': {\n",
    "\t\t\"selector__k\": [3, 5, 7, 9],\n",
    "\t\t\"selector__score_func\": [f_classif, mutual_info_classif, chi2],\n",
    "\t\t\"classifier__max_leaf_nodes\": [2, 3, 5, 8, 13],\n",
    "\t\t\"classifier__min_samples_split\": [2, 3, 4, 5, 6, 7],\n",
    "\t}\n",
    "}, {\n",
    "\t'name': 'AdaBoostClassifier',\n",
    "\t'classifier': Pipeline([\n",
    "\t\t('scaler', scaler),\n",
    "\t\t('selector', SelectKBest()),\n",
    "\t\t('classifier', ada_boost)\n",
    "\t]),\n",
    "\t'param_grid': {\n",
    "\t\t\"selector__k\": [3, 5, 7, 9],\n",
    "\t\t\"selector__score_func\": [f_classif, mutual_info_classif, chi2],\n",
    "\t\t\"classifier__n_estimators\": [50, 63, 75, 86, 100],\n",
    "\t\t\"classifier__learning_rate\": [0.50, 0.75, 1, 1.25, 1.5],\n",
    "\t}\n",
    "}]\n",
    "\n",
    "# {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "\n",
    "# Evaluate various classifiers\n",
    "print(\"Evaluating various classifiers.\")\n",
    "for index, estimator in enumerate(estimators):\n",
    "\tclassifier = estimator['classifier']\n",
    "\tgrid = estimator['param_grid']\n",
    "\tn_splits = 10\n",
    "\tsplitter = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.25).split\n",
    "\tscores = {\n",
    "\t\t'accuracy': [],\n",
    "\t\t'precision': [],\n",
    "\t\t'recall': [],\n",
    "\t}\n",
    "\tfor train_indices, test_indices in splitter(features, labels):\n",
    "\t\ttrain_features, test_features = features[train_indices], features[test_indices]\n",
    "\t\ttrain_labels, test_labels = labels[train_indices], labels[test_indices]\n",
    "\t\tpipe.fit(train_features, train_labels)\n",
    "\t\tscore = scorer(test_labels, pipe.predict(test_features))\n",
    "\t\tscores['accuracy'].append(score['accuracy'])\n",
    "\t\tscores['precision'].append(score['precision'])\n",
    "\t\tscores['recall'].append(score['recall'])\n",
    "\tmean_scores = {\n",
    "\t\t'accuracy': sum(scores['accuracy']) / n_splits,\n",
    "\t\t'precision': sum(scores['precision']) / n_splits,\n",
    "\t\t'recall': sum(scores['recall']) / n_splits,\n",
    "\t}\n",
    "\testimators[index].update({\n",
    "\t\t'mean_scores': mean_scores\n",
    "\t})\n",
    "\tparam_search = GridSearchCV(classifier, param_grid=grid)\n",
    "\tbest_params_ = param_search.fit(train_features, train_labels).best_params_\n",
    "\testimators[index].update({\n",
    "\t\t\"best_params_\": best_params_\n",
    "\t})\n",
    "\testimators[index].update({\n",
    "\t\t'best_estimator_': param_search.best_estimator_\n",
    "\t})\n",
    "\testimators[index].update({\n",
    "\t\t'best_features': best_features_extractor(param_search.best_estimator_.steps[1][1], features_list),\n",
    "\t\t'best_features_mask': param_search.best_estimator_.steps[1][1].get_support() \n",
    "\t})\n",
    "\tprint(\"Estimator: \", estimator['name'], \"scores: \", mean_scores)\n",
    "\n",
    "print(\"Performing synthetic tests with stratified sampling.\")\n",
    "for index, estimator in enumerate(estimators):\n",
    "    pipeline = estimator['best_estimator_']\n",
    "    scores = {\n",
    "      'accuracy': [],\n",
    "      'precision': [],\n",
    "      'recall': [],\n",
    "    }\n",
    "    n_splits = 100\n",
    "    splitter = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.25).split\n",
    "    for train_indices, test_indices in splitter(features, labels):\n",
    "        train_features, test_features = features[train_indices], features[test_indices]\n",
    "        train_labels, test_labels = labels[train_indices], labels[test_indices]\n",
    "        pipeline.fit(train_features, train_labels)\n",
    "        score = scorer(test_labels, pipeline.predict(test_features))\n",
    "        scores['accuracy'].append(score['accuracy'])\n",
    "        scores['precision'].append(score['precision'])\n",
    "        scores['recall'].append(score['recall'])\n",
    "    mean_scores = {\n",
    "      'accuracy': sum(scores['accuracy']) / n_splits,\n",
    "      'precision': sum(scores['precision']) / n_splits,\n",
    "      'recall': sum(scores['recall']) / n_splits,\n",
    "\t  }\n",
    "    print(estimator['name'], mean_scores, estimator['best_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('precision: ', 0.6666666666666666, False)\n",
      "('recall: ', 0.4, False)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# # Python uses call by object reference.  \n",
    "# # Estimators are objects; we can store them externally and \n",
    "# # reference them in the pipeline so that we can interact\n",
    "# # directly with them outside of the pipeline.\n",
    "\n",
    "# scaler = StandardScaler() # None\n",
    "# selector = SelectKBest() # k, score_func\n",
    "# # classifier = GaussianNB() # priors, var_smoothing\n",
    "# classifier = RandomForestClassifier() # n_estimators, \n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     ('scaler', scaler),\n",
    "#     ('selector', selector),\n",
    "#     ('classifier', classifier)\n",
    "# ])\n",
    "\n",
    "# param_grid = {\n",
    "#     \"selector__k\": [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "#     \"classifier__n_estimators\": [105, 110, 115, 120, 125, 130, 135],\n",
    "#     \"classifier__criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"classifier__min_samples_split\": [2, 3, 5]\n",
    "# }\n",
    "\n",
    "# scores = {\n",
    "#     'precision': 0,\n",
    "#     'accuracy': 0,\n",
    "#     'recall': 0,\n",
    "# }\n",
    "\n",
    "# while scores['precision'] < 0.30 or scores['recall'] < 0.30:\n",
    "#     clear_output(wait=True)\n",
    "#     StratifiedShuffleSplit(n_splits=1, test_size=0.25).split\n",
    "#     train_indices, test_indices = next(split(features, labels))\n",
    "#     train_features, test_features = features[train_indices], features[test_indices]\n",
    "#     train_labels, test_labels = labels[train_indices], labels[test_indices]\n",
    "\n",
    "#     # Prepare training and testing data\n",
    "#     param_search = GridSearchCV(pipeline, param_grid=param_grid)\n",
    "#     best_params_ = param_search.fit(train_features, train_labels).best_params_ # {'selector__k': 5}\n",
    "#     print(best_params_)\n",
    "#     tuned_pipe = Pipeline([\n",
    "#         ('scaler', scaler),\n",
    "#         ('selector', selector.set_params(**param_extractor(best_params_, \"selector\"))),\n",
    "#         ('classifier', classifier.set_params(**param_extractor(best_params_, \"classifier\")))\n",
    "#     ])\n",
    "\n",
    "#     tuned_pipe.fit(train_features, train_labels)\n",
    "#     scores = scorer(test_labels, tuned_pipe.predict(test_features))\n",
    "#     best_features = best_features_extractor(selector, features_list)\n",
    "#     print(\"precision: \", scores['precision'], scores['precision'] < 0.30)\n",
    "#     print(\"recall: \", scores['recall'],  scores['recall'] < 0.30)\n",
    "#     print(scores['precision'] < 0.30 or scores['recall'] < 0.30)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f92b2924b84ff19c1c3dc485f7644d4486f64738191026bf8e6de303969141b5"
  },
  "kernelspec": {
   "display_name": "Python 2.7.18 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
